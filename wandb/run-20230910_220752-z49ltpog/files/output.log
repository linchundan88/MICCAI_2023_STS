
using Segformer for training.
Some weights of the model checkpoint at nvidia/mit-b0 were not used when initializing SegformerForSemanticSegmentation: ['classifier.bias', 'classifier.weight']
- This IS expected if you are initializing SegformerForSemanticSegmentation from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing SegformerForSemanticSegmentation from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of SegformerForSemanticSegmentation were not initialized from the model checkpoint at nvidia/mit-b0 and are newly initialized: ['decode_head.batch_norm.running_mean', 'decode_head.classifier.weight', 'decode_head.linear_c.0.proj.weight', 'decode_head.linear_c.3.proj.bias', 'decode_head.classifier.bias', 'decode_head.linear_c.2.proj.bias', 'decode_head.batch_norm.num_batches_tracked', 'decode_head.batch_norm.bias', 'decode_head.linear_c.0.proj.bias', 'decode_head.linear_c.1.proj.weight', 'decode_head.linear_c.1.proj.bias', 'decode_head.linear_fuse.weight', 'decode_head.batch_norm.running_var', 'decode_head.linear_c.3.proj.weight', 'decode_head.linear_c.2.proj.weight', 'decode_head.batch_norm.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
  0%|          | 0/995 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "/mnt/d/PROJECTION/TianChi/STS-2D/train.py", line 209, in <module>
    train_loss = train_step(train_loader, model, criterion, optimizer, CFG.device, epoch)
  File "/mnt/d/PROJECTION/TianChi/STS-2D/train.py", line 68, in train_step
    for step, (image, label) in bar:
  File "/home/zy/anaconda3/envs/kaggle_torch/lib/python3.9/site-packages/tqdm/std.py", line 1178, in __iter__
    for obj in iterable:
  File "/home/zy/anaconda3/envs/kaggle_torch/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 633, in __next__
    data = self._next_data()
  File "/home/zy/anaconda3/envs/kaggle_torch/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1345, in _next_data
    return self._process_data(data)
  File "/home/zy/anaconda3/envs/kaggle_torch/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1371, in _process_data
    data.reraise()
  File "/home/zy/anaconda3/envs/kaggle_torch/lib/python3.9/site-packages/torch/_utils.py", line 644, in reraise
    raise exception
ValueError: Caught ValueError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/home/zy/anaconda3/envs/kaggle_torch/lib/python3.9/site-packages/torch/utils/data/_utils/worker.py", line 308, in _worker_loop
    data = fetcher.fetch(index)
  File "/home/zy/anaconda3/envs/kaggle_torch/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py", line 51, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/zy/anaconda3/envs/kaggle_torch/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py", line 51, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/mnt/d/PROJECTION/TianChi/STS-2D/datasets.py", line 20, in __getitem__
    data = self.transform(image=image, mask=label)
  File "/home/zy/anaconda3/envs/kaggle_torch/lib/python3.9/site-packages/albumentations/core/composition.py", line 205, in __call__
    data = t(**data)
  File "/home/zy/anaconda3/envs/kaggle_torch/lib/python3.9/site-packages/albumentations/core/transforms_interface.py", line 118, in __call__
    return self.apply_with_params(params, **kwargs)
  File "/home/zy/anaconda3/envs/kaggle_torch/lib/python3.9/site-packages/albumentations/core/transforms_interface.py", line 131, in apply_with_params
    res[key] = target_function(arg, **dict(params, **target_dependencies))
  File "/home/zy/anaconda3/envs/kaggle_torch/lib/python3.9/site-packages/albumentations/pytorch/transforms.py", line 83, in apply
    raise ValueError("Albumentations only supports images in HW or HWC format")
ValueError: Albumentations only supports images in HW or HWC format
train: