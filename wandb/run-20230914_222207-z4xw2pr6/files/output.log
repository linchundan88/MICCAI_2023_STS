using DynUNet for training.
train:
  0%|          | 0/548 [00:00<?, ?it/s]/home/zy/anaconda3/envs/kaggle_torch/lib/python3.9/site-packages/torch/nn/functional.py:2919: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.
  warnings.warn(
/mnt/d/PROJECTION/TianChi/STS-2D/train.py:78: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.
  torch.nn.utils.clip_grad_norm(model.parameters(), CFG.max_grad_norm)












































































































100%|██████████| 548/548 [03:41<00:00,  2.48it/s, epoch=1, gpu_mem=22.91 GB, loss=-49.8458, lr=3.00e-03]
100%|██████████| 1/1 [00:00<00:00,  6.36it/s, epoch=1, gpu_mem=2.47 GB, loss=-53.7384]
valid:
best_th=0.3, score up: 0.000000->0.176817
best_th=0.35, score up: 0.176817->0.177007
best_th=0.4, score up: 0.177007->0.177373
best_th=0.45, score up: 0.177373->0.178235
best_th=0.5, score up: 0.178235->0.180352
best_th=0.55, score up: 0.180352->0.183869
best_th=0.6, score up: 0.183869->0.188806
best_th=0.65, score up: 0.188806->0.195021
100%|██████████| 1/1 [00:00<00:00,  9.78it/s, epoch=1, gpu_mem=2.47 GB, loss=-43.9945]
100%|██████████| 1/1 [00:00<00:00,  6.67it/s, epoch=1, gpu_mem=2.47 GB, loss=-56.9529]
100%|██████████| 1/1 [00:00<00:00,  8.21it/s, epoch=1, gpu_mem=2.47 GB, loss=-54.3899]
100%|██████████| 1/1 [00:00<00:00,  8.43it/s, epoch=1, gpu_mem=2.47 GB, loss=-52.5326]
100%|██████████| 1/1 [00:00<00:00,  8.56it/s, epoch=1, gpu_mem=2.47 GB, loss=-42.1030]
best_th=0.3, score up: 0.000000->0.122219
best_th=0.3, score up: 0.000000->0.209132
best_th=0.35, score up: 0.209132->0.211198
best_th=0.4, score up: 0.211198->0.217372
best_th=0.45, score up: 0.217372->0.225711
best_th=0.5, score up: 0.225711->0.234228
best_th=0.55, score up: 0.234228->0.242515
best_th=0.6, score up: 0.242515->0.250737
best_th=0.65, score up: 0.250737->0.259061
best_th=0.3, score up: 0.000000->0.187823
best_th=0.35, score up: 0.187823->0.193610
best_th=0.4, score up: 0.193610->0.201247
best_th=0.45, score up: 0.201247->0.209149
best_th=0.5, score up: 0.209149->0.216174
best_th=0.55, score up: 0.216174->0.222124
best_th=0.6, score up: 0.222124->0.229726
best_th=0.65, score up: 0.229726->0.238383
best_th=0.3, score up: 0.000000->0.191781
best_th=0.35, score up: 0.191781->0.198557
best_th=0.4, score up: 0.198557->0.205350
best_th=0.45, score up: 0.205350->0.212823
best_th=0.5, score up: 0.212823->0.219442
best_th=0.55, score up: 0.219442->0.227600
best_th=0.6, score up: 0.227600->0.236158
best_th=0.65, score up: 0.236158->0.246234
best_th=0.3, score up: 0.000000->0.110346
train:













